# -*- coding: utf-8 -*-
"""Advanced_Model.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1mXiubVElATG885QTlg0cNgYAqLIERu1i
"""

import os
import gc
import numpy as np
import pandas as pd
import tensorflow as tf
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, LabelEncoder
from tensorflow.keras.layers import (
    Input, Dense, Dropout, GlobalAveragePooling2D,
    BatchNormalization, Attention, Lambda, Embedding,
    Flatten, Multiply, Concatenate
)
from tensorflow.keras.models import Model
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.applications import ResNet50
from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping, Callback
from sklearn.ensemble import RandomForestRegressor
import json

# -------------------------------
# Configurations
# -------------------------------
BATCH_SIZE       = 8
IMAGE_SIZE       = (224, 224)
TOP_EPOCHS       = 4
LR_INIT          = 3e-4
ENSEMBLE_SIZE    = 3

# -------------------------------
# 1. Data Loading & Preparation
# -------------------------------
def prepare_data(csv_path):
    df = pd.read_csv(csv_path).dropna().reset_index(drop=True)
    df['AGE'] = 2025 - df['YEAR BUILT']
    # df['PRICE_PER_SQFT'] = df['PRICE'] / df['SQUARE FEET']
    df['log_price'] = np.log1p(df['PRICE'])
    num_feats = [
        'BEDS','BATHS','SQUARE FEET','LOT SIZE','AGE',
        'DAYS ON MARKET','LATITUDE','LONGITUDE'
    ]
    scaler = StandardScaler()
    X_num = scaler.fit_transform(df[num_feats])
    X_prop = pd.get_dummies(df['PROPERTY TYPE'], drop_first=True).values
    city_le = LabelEncoder()
    city_ids = city_le.fit_transform(df['CITY'])
    X_struct = np.hstack([X_num, X_prop])
    df['decile'] = pd.qcut(df['PRICE'], 10, labels=False)
    idx_train, idx_val = train_test_split(
        np.arange(len(df)), test_size=0.2,
        stratify=df['decile'], random_state=42
    )
    return {
        'X_struct_train': X_struct[idx_train],
        'X_struct_val':   X_struct[idx_val],
        'city_train':     city_ids[idx_train],
        'city_val':       city_ids[idx_val],
        'paths_train':    df['PHOTO_PATH'].values[idx_train].astype(str),
        'paths_val':      df['PHOTO_PATH'].values[idx_val].astype(str),
        'y_train':        df['log_price'].values[idx_train],
        'y_val':          df['log_price'].values[idx_val],
        'input_dim':      X_struct.shape[1],
        'n_cities':       len(city_le.classes_),
        'scaler':         scaler
    }

# -------------------------------
# 2. tf.data Pipeline
# -------------------------------
def decode_and_preprocess(path, augment=False):
    img = tf.io.read_file(path)
    img = tf.image.decode_jpeg(img, channels=3)
    img = tf.image.resize(img, IMAGE_SIZE)
    img = img / 255.0
    if augment:
        img = tf.image.random_flip_left_right(img)
        img = tf.image.random_brightness(img, 0.2)
        img = tf.image.random_contrast(img, 0.8, 1.2)
    return img

def make_dataset(paths, X_struct, city_ids, y, augment=False):
    ds = tf.data.Dataset.from_tensor_slices((paths, X_struct, city_ids, y))
    if augment:
        ds = ds.shuffle(10000)
    ds = ds.map(
        lambda p, x, c, label: (
            {
                'image_input': decode_and_preprocess(p, augment),
                'structured_input': x,
                'city_input': c
            }, label),
        num_parallel_calls=tf.data.AUTOTUNE
    )
    return ds.batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)

# -------------------------------
# 3. Model Definition w/ Attention Fusion (unchanged)
# -------------------------------
def build_attention_model(input_dim_struct, n_cities, emb_dim=16, proj_dim=128):
    img_in = Input(shape=(*IMAGE_SIZE,3), name='image_input')
    backbone = ResNet50(weights='imagenet', include_top=False, input_tensor=img_in)
    backbone.trainable = False
    feat_map = backbone.output
    img_feat = GlobalAveragePooling2D()(feat_map)
    img_proj = Dense(proj_dim, activation='relu')(img_feat)
    struct_in = Input(shape=(input_dim_struct,), name='structured_input')
    s = Dense(64, activation='relu')(struct_in)
    s = Dropout(0.2)(s)
    city_in = Input(shape=(), dtype='int32', name='city_input')
    e = Embedding(input_dim=n_cities, output_dim=emb_dim)(city_in)
    e = Flatten()(e)
    e = Dense(16, activation='relu')(e)
    tab_feat = Concatenate()([s, e])
    tab_proj = Dense(proj_dim, activation='relu')(tab_feat)
    gate = Dense(proj_dim, activation='sigmoid')(Concatenate()([img_proj, tab_proj]))
    inv_gate = Lambda(lambda x: 1.0 - x, name='invert_gate')(gate)
    img_part = Multiply(name='img_gate')([gate, img_proj])
    tab_part = Multiply(name='tab_gate')([inv_gate, tab_proj])
    fused = Concatenate(name='fusion')([img_part, tab_part])
    img_q = Lambda(lambda x: tf.expand_dims(x,1))(img_proj)
    tab_k = Lambda(lambda x: tf.expand_dims(x,1))(tab_proj)
    attn = Attention()([img_q, tab_k])
    inv_attn = Lambda(lambda x: 1.0 - x, name='invert_attn')(attn)
    img_gate = Multiply(name='img_gate')([img_proj, attn])
    tab_gate = Multiply(name='tab_gate')([tab_proj, inv_attn])
    fused = Concatenate(name='fusion')([img_gate, tab_gate])
    x = Dense(128, activation='relu')(fused)
    x = BatchNormalization()(x)
    x = Dropout(0.3)(x)
    out_log = Dense(1, name='log_price')(x)
    model = Model(inputs=[img_in, struct_in, city_in], outputs=out_log)
    model.backbone = backbone
    return model

# -------------------------------
# 4. Snapshot Ensembles
# -------------------------------
class SnapshotCallback(tf.keras.callbacks.Callback):
    """
    Cosine‑annealing LR schedule + snapshot saving.
    Saves weights to   path_template.format(idx)   at the end of each cycle.
    """
    def __init__(self, total_epochs, n_snapshots, lr_max, path_template):
        super().__init__()
        self.T   = total_epochs
        self.M   = n_snapshots
        self.lr_max = lr_max
        self.path_template = path_template
        # e.g. [3, 6, 9] for 10 epochs & 3 snapshots
        self.snapshot_epochs = np.linspace(0, total_epochs,
                                           n_snapshots+1,
                                           dtype=int)[1:]

    # --- cosine‑annealing LR ---
    def on_epoch_begin(self, epoch, logs=None):
        T_i = self.T // self.M              # length of one cycle
        cos_inner = np.pi * (epoch % T_i) / T_i
        lr = self.lr_max * 0.5 * (np.cos(cos_inner) + 1)

        # works across TF 2.9 → 2.16
        if hasattr(self.model.optimizer, "lr"):          # legacy alias
            self.model.optimizer.lr.assign(lr)
        else:                                            # modern API
            self.model.optimizer.learning_rate.assign(lr)


    # --- save snapshot at the end of each cycle ---
    def on_epoch_end(self, epoch, logs=None):
        if (epoch + 1) in self.snapshot_epochs:
            idx = self.snapshot_epochs.tolist().index(epoch + 1) + 1
            path = self.path_template.format(idx)
            os.makedirs(os.path.dirname(path), exist_ok=True)
            self.model.save_weights(path)
            print(f"\n✅  Saved snapshot {idx} to {path}")



def train_snapshot_ensemble(data):
    models = []
    train_ds = make_dataset(data['paths_train'], data['X_struct_train'], data['city_train'], data['y_train'], augment=True)
    val_ds = make_dataset(data['paths_val'], data['X_struct_val'], data['city_val'], data['y_val'], augment=False)
    base_model = build_attention_model(data['input_dim'], data['n_cities'])
    base_model.compile(
        optimizer=Adam(LR_INIT),
        loss=tf.keras.losses.Huber(),
        metrics=['mse','mae']
    )
    #snapshot_cb = SnapshotCallback(TOP_EPOCHS, ENSEMBLE_SIZE, LR_INIT)
    reduce_lr = ReduceLROnPlateau(patience=3, factor=0.5, verbose=1)
    es = EarlyStopping(patience=5, restore_best_weights=True)

    SNAP_DIR = '/content/drive/MyDrive/CSC 374/Project/Final Project Code/results'
    SNAP_TMPL = os.path.join(SNAP_DIR, 'snapshot_{}.weights.h5')

    snapshot_cb = SnapshotCallback(
            total_epochs = TOP_EPOCHS,
            n_snapshots  = ENSEMBLE_SIZE,
            lr_max       = LR_INIT,
            path_template= SNAP_TMPL)

    base_model.fit(
            train_ds,
            validation_data = val_ds,
            epochs   = TOP_EPOCHS,
            callbacks= [snapshot_cb,
                        ReduceLROnPlateau(patience=3, factor=0.5, verbose=1),
                        EarlyStopping(patience=5, restore_best_weights=True)]
    )

    for i in range(1, ENSEMBLE_SIZE + 1):
        m = build_attention_model(data['input_dim'], data['n_cities'])
        m.compile(optimizer=Adam(LR_INIT),
                  loss=tf.keras.losses.Huber(),
                  metrics=['mse', 'mae'])
        m.load_weights(SNAP_TMPL.format(i))
        models.append(m)
        # Add path to file when loading weights

    return models

# -------------------------------
# 5. Feature-Level Ensembling
# -------------------------------
def feature_level_ensemble(data):
    # Build feature extractor from frozen snapshot
    model = build_attention_model(data['input_dim'], data['n_cities'])
    model.load_weights(f'/content/drive/MyDrive/CSC 374/Project/Final Project Code/results/snapshot_{ENSEMBLE_SIZE}.weights.h5')
    extractor = Model(inputs=model.inputs, outputs=model.get_layer('fusion').output)
    # Helper to create input-only dataset
    def input_ds(paths, X_struct, city_ids):
        ds = tf.data.Dataset.from_tensor_slices((paths, X_struct, city_ids))
        ds = ds.map(lambda p, x, c: ({
            'image_input': decode_and_preprocess(p, False),
            'structured_input': x,
            'city_input': c
        }), num_parallel_calls=tf.data.AUTOTUNE)
        return ds.batch(BATCH_SIZE)
    feats_train = extractor.predict(input_ds(data['paths_train'], data['X_struct_train'], data['city_train']))
    feats_val   = extractor.predict(input_ds(data['paths_val'],   data['X_struct_val'],   data['city_val']))
    rf = RandomForestRegressor(n_estimators=100)
    rf.fit(feats_train, data['y_train'])
    preds = rf.predict(feats_val)
    mae = np.mean(np.abs(preds - data['y_val']))
    mse = np.mean((preds - data['y_val'])**2)
    print(f"Feature-level RF MAE: {mae:.4f}, MSE: {mse:.4f}")

# -------------------------------
# 6. Main
# -------------------------------
def main():
    data = prepare_data('/content/drive/MyDrive/CSC 374/Project/Data/all_listings.csv')
    # Snapshot ensemble
    snap_models = train_snapshot_ensemble(data)
    val_ds = make_dataset(data['paths_val'], data['X_struct_val'], data['city_val'], data['y_val'], augment=False)
    y_pred_snap = sum([m.predict(val_ds) for m in snap_models]) / len(snap_models)
    y_true = data['y_val']
    y_pred = np.expm1(y_pred_snap)
    y_true_exp = np.expm1(y_true)
    mae = np.mean(np.abs(y_pred - y_true_exp))
    mse = np.mean((y_pred - y_true_exp)**2)
    print(f"Snapshot Ensemble MAE: ${mae:,.2f}, MSE: {mse:,.2f}")
    # Feature-level ensemble
    feature_level_ensemble(data)
    # Save final snapshot model and artifacts
    model = snap_models[-1]
    model.save('/content/drive/MyDrive/CSC 374/Project/Final Project Code/results/m4_model.keras')
    import joblib
    joblib.dump(data['scaler'], '/content/drive/MyDrive/CSC 374/Project/Final Project Code/results/m4_scaler.pkl')
    json.dump({'prop_dim': data['input_dim']}, open('/content/drive/MyDrive/CSC 374/Project/Final Project Code/results/m4_meta.json','w'))
    # Save eval stats
    with open('/content/drive/MyDrive/CSC 374/Project/Final Project Code/results/m4_results.txt','w') as f:
        f.write(f"MAE: {mae}\nMSE: {mse}\n")
if __name__ == '__main__':
    main()